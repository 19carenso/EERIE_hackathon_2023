{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f117c1f-b9d7-406b-bda1-dfb7466843b7",
   "metadata": {},
   "source": [
    "## Example for eddy identification and tracking for daily data using py-eddy-tracker (for IFS/FESOM output)\n",
    "\n",
    "- Basic setup to identify, track and composite eddies uses ICON output from known paths. Please refer to noteboook examples [howto-IDtrackcompeddy-daily.ipynb](https://github.com/eerie-project/EERIE_hackathon_2023/blob/main/ICON/ICON-O/howto-IDtrackcompeddy-daily.ipynb)  and [howto-eddycompositeotherfields-daily.ipynb]((https://github.com/eerie-project/EERIE_hackathon_2023/blob/main/ICON/ICON-O/howto-eddycompositeotherfields-daily.ipynb) (Dian Putrasahan)\n",
    "- py-eddy-tracker reads in netcdf file but does not know how to use xarray. This issue was dealt with in [pyeddytracker-intake-xarray-parallel-demo.ipynb](https://github.com/eerie-project/EERIE_hackathon_2023/blob/main/RESULTS/pyeddytracker_xarray_dask_parallel/pyeddytracker-intake-xarray-parallel-demo.ipynb) (Aaron Wienkers). Furthermore, the code uses dask for parallelisation. \n",
    "- Now, feeding py-eddy-tracker with xarray obtained from reading in with intake catalog is possible, so here's an example of how it is done (Aaron Wienkers and Dian Putrasahan)\n",
    "- Parameter choices for py-eddy-tracker closely follow those used for AVISO, following [recommendation from py-eddy-tracker author](https://github.com/AntSimi/py-eddy-tracker/discussions/198). \n",
    "\n",
    "| Parameter (identification) | Value | Description |\n",
    "| ------------------------------- | ------------ | --------------------------- |\n",
    "| wavelength (Bessel filter) | 700 km | spatial cutoff for high pass filter in km |\n",
    "| wavelength_order (filter) | 1 | |\n",
    "| step_ht | 0.002 m | intervals to search for closed contours (m) |\n",
    "| shape error | 70 | Error max (%) between ratio of circle fit and contour |\n",
    "| nb_step_to_be_mle | 0 (default 2?) | don't allow micro relief in an eddy, used for computing amplitude | \n",
    "| sampling (affects storage) | Not set (default 50) | affects storage, using 20-30 is acceptable |\n",
    "| pixel_limit | Not set (default None) | Min and max pixel count for valid contour (5, 2000)  |\n",
    "| presampling_multiplier | Not set (default 10) | |\n",
    "| sampling_method | Not set (default visvalingam) | |\n",
    "| precision | Not set (default None) | |\n",
    "\n",
    "\n",
    "| Parameter (tracking) | Value |\n",
    "| ------------------------ | ------------ |\n",
    "| cmin | 0.05 |\n",
    "| virtual | 4 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65059402-3fc1-4f8b-8858-402bdbe2ec2c",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60837cea-2ea1-4256-9bdf-cd5b07faefbf",
   "metadata": {},
   "source": [
    "#### Eddy identification based on 0.25deg grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57896936-0dab-447c-9487-3b9ea0f3a3d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.interpolate import CloughTocher2DInterpolator, LinearNDInterpolator, NearestNDInterpolator\n",
    "import glob\n",
    "import intake\n",
    "import intake_xarray\n",
    "import dask\n",
    "import pandas as pd\n",
    "dask.config.set({\"array.slicing.split_large_chunks\": True}) \n",
    "\n",
    "from py_eddy_tracker.dataset.grid import RegularGridDataset\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import io\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195e9226-0ece-49ed-95a7-e28e68ee5892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Start Parallel Client\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "# Note: Could also use Dask Distributed Client\n",
    "n_cpu = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "441b14b2-2c98-40b1-967c-da22a37a6d31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daily', 'monthly']\n"
     ]
    }
   ],
   "source": [
    "cat = intake.open_catalog(\"https://raw.githubusercontent.com/eerie-project/intake_catalogues/main/eerie.yaml\")\n",
    "model = 'ifs-fesom2-sr'\n",
    "expid = 'eerie-control-1950'\n",
    "gridspec = 'gr025'\n",
    "cat_regrid = cat['dkrz.disk.model-output'][model][expid]['ocean'][gridspec]\n",
    "print(list(cat_regrid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07188a6-49e3-4770-a762-c33f52f9e4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = cat_regrid['daily'].to_dask()\n",
    "varname = 'ssh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e031b84-98bf-4ff0-9017-89172db9c875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ds_subset = ds.sel(time=slice('1951-01-01','1956-12-31'))\n",
    "ds_subset = ds\n",
    "datearr = np.array([pd.Timestamp(t).to_pydatetime() for t in ds_subset.time.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05e3d02c-5195-4080-83ef-27783c808e36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "scratch = '/scratch/m/m300466/'\n",
    "datadir = scratch+expid+'/'+gridspec+'/'\n",
    "outdir1 = datadir+'/'+model+'/eddytrack/'\n",
    "\n",
    "wavelength=700\n",
    "outdir = outdir1+'sm'+str(wavelength)+'/'\n",
    "\n",
    "if not os.path.exists(datadir+'/'+model):\n",
    "    os.makedirs(datadir+'/'+model)\n",
    "if not os.path.exists(outdir1):\n",
    "    os.makedirs(outdir1)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5d9a2-f760-43b8-aa55-73702229cc60",
   "metadata": {},
   "source": [
    "## ID eddies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827818ca-d01c-4cb6-86a6-9cedbabc5d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detection(ncfile, varname, date): \n",
    "    #Follow AVISO and Malcolm's parameter choices\n",
    "    wavelength=700  #choice of spatial cutoff for high pass filter in km\n",
    "    step_ht=0.002 #intervals to search for closed contours (5mm in this case)\n",
    "    g = RegularGridDataset(None, \"lon\", \"lat\", centered=True, nc4file=ncfile)  # NOTE: Using 'None' for the .nc file path then requires specifying directly the netcdf4 variable in memory\n",
    "    g.add_uv(varname)\n",
    "    g.bessel_high_filter(varname, wavelength, order=1)\n",
    "        \n",
    "    a, c = g.eddy_identification(varname, \"u\", \"v\", \n",
    "    date,  # Date of identification\n",
    "    step_ht,  # step between two isolines of detection (m)\n",
    "    #pixel_limit=(50, 400),  # Min and max pixel count for valid contour\n",
    "    nb_step_to_be_mle = 0,  # don't allow micro relief in an eddy, used for computing amplitude\n",
    "    #sampling = 20,  #affects storage, default 50, try between 20-30\n",
    "    shape_error=70  # Error max (%) between ratio of circle fit and contour\n",
    "    )\n",
    "    return a,c,g\n",
    "\n",
    "# Parallel function wrapper to the for-loop \n",
    "def delayed_ID_and_save(date, tt):\n",
    "    varname='ssh'\n",
    "    \n",
    "    # Load data from xarray into netcdf4 type\n",
    "    da_ssh = ds_subset.isel(time=tt)\n",
    "    # da_ssh = ds_oce.isel(time=tt).ssh\n",
    "    da_ssh.time.encoding.pop(\"_FillValue\",None)\n",
    "    da_netcdf = Dataset('in-mem-file', mode='r', memory=da_ssh.to_netcdf())\n",
    "    \n",
    "    #print('Identifying daily eddies for '+date.strftime('%Y%m%d'))\n",
    "    a_filtered, c_filtered, g_filtered = detection(da_netcdf,varname,date)\n",
    "    with Dataset(date.strftime(outdir+\"eddyID_anticyclonic_\"+date.strftime('%Y%m%d')+\".nc\"), \"w\") as h:\n",
    "        a_filtered.to_netcdf(h)\n",
    "    with Dataset(date.strftime(outdir+\"eddyID_cyclonic_\"+date.strftime('%Y%m%d')+\".nc\"), \"w\") as h:\n",
    "        c_filtered.to_netcdf(h)\n",
    "    del a_filtered\n",
    "    del c_filtered\n",
    "    del g_filtered\n",
    "    del date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a6c22-2234-4941-af27-5fa9377343bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stdout\n",
    "# ID all of the eddies in the ds_subset in parallel\n",
    "with ProcessPoolExecutor(max_workers=n_cpu) as executor:\n",
    "    results = list(executor.map(delayed_ID_and_save, datearr, range(len(datearr))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7280b4-f090-4f73-9fad-06ecf7d9531f",
   "metadata": {},
   "source": [
    "## Track Eddies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad582660-c7b6-41b2-adf2-aa021b95945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "from py_eddy_tracker.featured_tracking.area_tracker import AreaTracker\n",
    "from py_eddy_tracker.tracking import Correspondances\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9d9dc7-4e03-4947-a6b1-620495528b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions from eddy-tracking.py (aided by Malcolm Roberts)\n",
    "def tracking(file_objects, previous_correspondance, eddy_type, zarr=False, nb_obs_min=10, raw=True, cmin=0.05, virtual=4):\n",
    "    # %%\n",
    "    # We run a tracking with a tracker which uses contour overlap, on first time step\n",
    "    output_dir = os.path.dirname(previous_correspondance)\n",
    "    class_kw = dict(cmin=cmin)\n",
    "    if not os.path.isfile(previous_correspondance):\n",
    "        c = Correspondances(\n",
    "            datasets=file_objects, class_method=AreaTracker, \n",
    "            class_kw=class_kw, virtual=virtual\n",
    "        )\n",
    "        c.track()\n",
    "        c.prepare_merging()\n",
    "    else:\n",
    "        c = Correspondances(\n",
    "            datasets=file_objects, class_method=AreaTracker, \n",
    "            class_kw=class_kw, virtual=virtual,\n",
    "            previous_correspondance=previous_correspondance\n",
    "        )\n",
    "        c.track()\n",
    "        c.prepare_merging()\n",
    "        c.merge()\n",
    "\n",
    "    new_correspondance = previous_correspondance[:-3]+'_new.nc'\n",
    "    with Dataset(new_correspondance, \"w\") as h:\n",
    "        c.to_netcdf(h)\n",
    "\n",
    "    try:\n",
    "        # test can read new file, and then move to replace old file\n",
    "        nc = Dataset(new_correspondance, 'r')\n",
    "        os.rename(new_correspondance, previous_correspondance)\n",
    "    except:\n",
    "        raise Exception('Error opening new correspondance file '+new_correspondance)\n",
    "\n",
    "    write_obs_files(c, raw, output_dir, zarr, eddy_type, nb_obs_min)\n",
    "    \n",
    "\n",
    "def write_obs_files(c, raw, output_dir, zarr, eddy_type, nb_obs_min):\n",
    "    kw_write = dict(path=output_dir, zarr_flag=zarr, sign_type=eddy_type)\n",
    "\n",
    "    fout = os.path.join(output_dir, eddy_type+'_untracked.nc')\n",
    "    c.get_unused_data(raw_data=raw).write_file(\n",
    "        filename=fout\n",
    "    )\n",
    "\n",
    "    short_c = c._copy()\n",
    "    short_c.shorter_than(size_max=nb_obs_min)\n",
    "    short_track = short_c.merge(raw_data=raw)\n",
    "\n",
    "    if c.longer_than(size_min=nb_obs_min) is False:\n",
    "        long_track = short_track.empty_dataset()\n",
    "    else:\n",
    "        long_track = c.merge(raw_data=raw)\n",
    "\n",
    "    # We flag obs\n",
    "    if c.virtual:\n",
    "        long_track[\"virtual\"][:] = long_track[\"time\"] == 0\n",
    "        long_track.normalize_longitude()\n",
    "        long_track.filled_by_interpolation(long_track[\"virtual\"] == 1)\n",
    "        short_track[\"virtual\"][:] = short_track[\"time\"] == 0\n",
    "        short_track.normalize_longitude()\n",
    "        short_track.filled_by_interpolation(short_track[\"virtual\"] == 1)\n",
    "\n",
    "    print(\"Longer track saved have %d obs\", c.nb_obs_by_tracks.max())\n",
    "    print(\n",
    "        \"The mean length is %d observations for long track\",\n",
    "        c.nb_obs_by_tracks.mean(),\n",
    "    )\n",
    "\n",
    "    fout = os.path.join(output_dir, eddy_type+'_tracks.nc')\n",
    "    long_track.write_file(filename=fout)\n",
    "    fout = os.path.join(output_dir, eddy_type+'_short.nc')\n",
    "    short_track.write_file(\n",
    "        #filename=\"%(path)s/%(sign_type)s_track_too_short.nc\", **kw_write\n",
    "        filename=fout\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00624077-39c9-405f-9178-1069e1a95cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yrrng=datearr[0].year\n",
    "tracker_dir=outdir+'tracks/'\n",
    "if not os.path.exists(tracker_dir):\n",
    "    os.makedirs(tracker_dir)\n",
    "\n",
    "nb_obs_min = 10 # minimum of 10 points in track to be considered a long trajectory\n",
    "raw = False # \n",
    "cmin = 0.05 # minimum contour\n",
    "virtual = 4 # number of consecutive timesteps with missing detection allowed\n",
    "class_kw = dict(cmin=cmin)\n",
    "zarr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ef4f7c-1a75-455b-ba48-cac3dce995e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search files  /scratch/m/m300466/eerie-control-1950/gr025//ifs-fesom2-sr/eddytrack/sm700/eddyID_anticyclonic_????????.nc\n",
      "Longer track saved have %d obs 3179\n",
      "The mean length is %d observations for long track 48.690123532386714\n"
     ]
    }
   ],
   "source": [
    "eddy_type='anticyclonic'\n",
    "previous_correspondance = os.path.join(tracker_dir, eddy_type+'_correspondance.nc')\n",
    "# search = os.path.join(outdir+'eddyID_'+eddy_type+'_'+str(yrrng)+'????.nc')\n",
    "search = os.path.join(outdir+'eddyID_'+eddy_type+'_????????.nc')\n",
    "print('search files ',search)\n",
    "file_objects = sorted(glob.glob(search))\n",
    "tracking(file_objects, previous_correspondance, eddy_type, zarr=zarr, nb_obs_min=nb_obs_min, raw=raw, cmin=cmin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b581c88-342d-42a1-a89e-d6f1239d9bea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search files  /scratch/m/m300466/eerie-control-1950/gr025//ifs-fesom2-sr/eddytrack/sm700/eddyID_cyclonic_????????.nc\n"
     ]
    }
   ],
   "source": [
    "eddy_type='cyclonic'  #need to include all changes with eddy_type\n",
    "previous_correspondance = os.path.join(tracker_dir, eddy_type+'_correspondance.nc')\n",
    "search = os.path.join(outdir+'eddyID_'+eddy_type+'_????????.nc')\n",
    "print('search files ',search)\n",
    "file_objects = sorted(glob.glob(search))\n",
    "tracking(file_objects, previous_correspondance, eddy_type, zarr=zarr, nb_obs_min=nb_obs_min, raw=raw, cmin=cmin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1917ff7-5f64-4966-a23e-c4a26fb98b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Files created in /work/bm1344/m300466/reg25/ifsfesom/eddytrack_test/tracks/\n",
    "\n",
    "# anticyclonic_dm_correspondance.nc\n",
    "# anticyclonic_untracked.nc\n",
    "# anticyclonic_tracks.nc\n",
    "# anticyclonic_short.nc\n",
    "# cyclonic_dm_correspondance.nc\n",
    "# cyclonic_untracked.nc\n",
    "# cyclonic_tracks.nc\n",
    "# cyclonic_short.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b5326-b685-4e15-af11-8ba18b1e74dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eddyenv_dap_v1",
   "language": "python",
   "name": "eddyenv_dap_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
