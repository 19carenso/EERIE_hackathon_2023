{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95fe27b-c8d9-41d9-8de3-34a7969f9017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### The primary script taken from Vasco MÃ¼ller ###\n",
    "### The script is adapted to work with EERIE IFS-FESOM data by Rohit Ghosh ###\n",
    "\n",
    "import pyfesom2 as pf\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3730412-ebff-4315-9f80-a4df860cee02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mesh_path='/work/ab0995/a270088/meshes/NG5/'\n",
    "diag = xr.open_dataset((mesh_path+'fesom.mesh.diag.nc'))  # fesom.mesh.diag.nc contains the dx/dy operators (basically just vectors of the same size as u/v)\n",
    "ddx = diag['gradient_sca_x']\n",
    "ddy = diag['gradient_sca_y']\n",
    "elem = (diag['elements']-1).T  #element indices are saved in Fortran format, starting from 1 instead of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa309b68-d37b-476d-9f98-349493e35573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "/work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n",
      "The usepickle == True)\n",
      "The pickle file for FESOM2 exists.\n",
      "The mesh will be loaded from /work/ab0995/a270088/meshes/NG5/pickle_mesh_py3_fesom2\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "depth=100 # 100m \n",
    "iz = np.argmin(np.abs(diag.nz1.values+depth)) #find the closest level in the model, depth in diag.nz1 is negative, that is why I use +depth\n",
    "\n",
    "# Define the years and months\n",
    "years = ['1971']  # Example list of years\n",
    "months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']  # List of months\n",
    "\n",
    "# Loop over years and months\n",
    "for year in years:\n",
    "    for mon in months:\n",
    "        data_path='/work/bm1344/a270228/EERIE_NextG_Hackathon/IFS-FESOM_CONTROL-1950/tco1279-NG5/{year}/FESOM/native/daily/'\n",
    "\n",
    "        # Use string formatting to replace {year} in the data_path\n",
    "        data_path = data_path.format(year=year)\n",
    "\n",
    "        unod = xr.open_mfdataset((data_path+f'fesom_unod_{year}{mon}*-{year}{mon}*_daily-NG5.nc'),chunks={'time':40,'nod2':200})['unod'].astype('float32').isel(nz1=iz)\n",
    "        vnod = xr.open_mfdataset((data_path+f'fesom_vnod_{year}{mon}*-{year}{mon}*_daily-NG5.nc'),chunks={'time':40,'nod2':200})['vnod'].astype('float32').isel(nz1=iz)\n",
    "        time= xr.open_mfdataset((data_path+f'fesom_unod_{year}{mon}*-{year}{mon}*_daily-NG5.nc'),chunks={'time':40,'nod2':200})['time'].astype('float32')\n",
    "\n",
    "        n= time.size\n",
    "\n",
    "        mesh= pf.load_mesh(mesh_path)\n",
    "\n",
    "        #Initialize empty lists to store results for each time step\n",
    "        div_list = []\n",
    "        curl_list = []\n",
    "\n",
    "        for dd in range(n):  # Looping over 0 to 30 for the time dimension\n",
    "            v = vnod[dd, :].compute()\n",
    "            u = unod[dd, :].compute()\n",
    "    \n",
    "            ##Calculating Curl##\n",
    "            dv_dx = (ddx * v[elem]).sum(dim='n3') \n",
    "            du_dy = (ddy * u[elem]).sum(dim='n3')\n",
    "            curl = dv_dx - du_dy\n",
    "\n",
    "            ## Curl at Node ##\n",
    "            curl = pf.tonodes(curl, mesh)\n",
    "            curl = xr.DataArray(curl, coords=v.coords, dims=v.dims)\n",
    "    \n",
    "            ## Calculating divergence ##\n",
    "            dv_dy = (ddy * v[elem]).sum(dim='n3') \n",
    "            du_dx = (ddx * u[elem]).sum(dim='n3') \n",
    "            div = du_dx + dv_dy\n",
    "\n",
    "            ## Divergence at Node ##\n",
    "            div = pf.tonodes(div, mesh)\n",
    "            ## Changing div to a Xarray object ##\n",
    "            div = xr.DataArray(div, coords=v.coords, dims=v.dims)\n",
    "    \n",
    "           # Append div and curl to lists\n",
    "            div_list.append(div)\n",
    "            curl_list.append(curl)\n",
    "\n",
    "            # Combine the lists into Xarray DataArrays along the time dimension\n",
    "            divergence = xr.concat(div_list, dim='time')\n",
    "            curl = xr.concat(curl_list, dim='time')\n",
    "\n",
    "            # Add variable attributes\n",
    "            divergence.attrs['long_name'] = 'Divergence of Ocean surface water velocity'\n",
    "            divergence.attrs['units'] = '1/s'\n",
    "\n",
    "            # Create a Dataset containing the DataArray\n",
    "            dv = xr.Dataset({'divergence': divergence})\n",
    "\n",
    "            dv.to_netcdf(f\"/work/bm1344/a270228/div_curl/fesom_divergence_{year}{mon}_daily-NG5.nc\")\n",
    "\n",
    "            # Add variable attributes\n",
    "            curl.attrs['long_name'] = 'Curl of Ocean surface water velocity'\n",
    "            curl.attrs['units'] = '1/s'\n",
    "\n",
    "            # Create a Dataset containing the DataArray\n",
    "            cl = xr.Dataset({'curl': curl})\n",
    "\n",
    "            cl.to_netcdf(f\"/work/bm1344/a270228/div_curl/fesom_curl_{year}{mon}_daily-NG5.nc\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1 Python 3 (based on the module python3/2023.01)",
   "language": "python",
   "name": "python3_2023_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
