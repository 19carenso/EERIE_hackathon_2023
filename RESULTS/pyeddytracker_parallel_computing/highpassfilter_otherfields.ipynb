{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60837cea-2ea1-4256-9bdf-cd5b07faefbf",
   "metadata": {},
   "source": [
    "# High pass filter other fields (already on 0.25deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5797603-ff44-4973-8c43-e973ccbb5fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from py_eddy_tracker.dataset.grid import RegularGridDataset\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "#Read in example SSH data that has been mapped onto a 0.25deg regular grid.\n",
    "\n",
    "expid='erc1011'\n",
    "varname='to'\n",
    "fq='dm'\n",
    "\n",
    "# path to access ssh data to identify eddies\n",
    "datadir = '/work/bm1344/k203123/reg25/erc1011/'+varname+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ba889-0440-4d74-936e-e0be16c8e283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "#find datafiles\n",
    "datafiles = sorted(glob.glob(datadir+\"*.nc\"))\n",
    "print('# data files for identifying eddies: ', len(datafiles))\n",
    "print('datafiles for identifying eddies: ', datafiles)\n",
    "#create datetime objects for 2002 to 2008; each year one entry in list\n",
    "datearrs = []\n",
    "for x in range(len(datafiles)):\n",
    "    yyyy=int(2002+x)\n",
    "    datearrs.append(np.arange(datetime(yyyy,1,1), datetime(yyyy+1,1,1), timedelta(days=1)).astype(datetime))\n",
    "print('datearrs: ', datearrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7290b6f-897e-48fc-b06a-45fdc8d29ac4",
   "metadata": {},
   "source": [
    "### Start SLURM cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ec744-e79e-4f3d-bea9-74b9414a609c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8181073-969a-4dc4-bb66-e30eb855b2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4815fd-ef7f-4793-8953-6adec9037d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(name='dask-cluster',\n",
    "                      cores=10,\n",
    "                      memory='256GB',\n",
    "                      processes=5,\n",
    "                      interface='ib0',\n",
    "                      queue='compute',\n",
    "                      account='mh0033',\n",
    "                      walltime='01:00:00',\n",
    "                      asynchronous=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f271aacd-0431-4a42-9671-342d92d37529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(cores=200)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b31d020-1f78-4c68-8348-495d74629557",
   "metadata": {},
   "source": [
    "### Define high pass filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54012c0d-f097-423f-bd6d-7aa3f964462c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def besselhighpass(varfile, varname, datearr, tt, wavelength):\n",
    "    #wavelength: choice of spatial cutoff for high pass filter in km\n",
    "    outdir = '/path/to/output/data/erc1011_eddytrack/to_hbp/'+'wv_'+str(int(wavelength))+'/'\n",
    "    step_ht=0.005 #intervals to search for closed contours (5mm in this case)\n",
    "    g = RegularGridDataset(varfile, \"lon\", \"lat\", centered=True, indexs = dict(time=tt))\n",
    "    g.dimensions['time']=1  #extracts only one time step that was specified by indexs = dict(time=tt)\n",
    "    if varname=='rho':\n",
    "        g.bessel_high_filter('rhopoto', wavelength, order=1)\n",
    "    else:\n",
    "        g.bessel_high_filter(varname, wavelength, order=1) #perfroms only on 1 time index\n",
    "    date = datearr[tt] # detect each timestep individually because of memory issues\n",
    "    if varname=='to' or varname=='so' or varname=='rho':\n",
    "        zidx=1\n",
    "        g.write(outdir+expid+'_'+varname+'_'+str(zidx)+'_'+fq+'_'+date.strftime('%Y%m%d')+'_IFS25_hp'+str(wavelength)+'.nc')\n",
    "    else:\n",
    "        g.write(outdir+expid+'_'+varname+'_'+fq+'_'+date.strftime('%Y%m%d')+'_IFS25_hp'+str(int(wavelength))+'.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcbf1f1-a3b5-42a3-8ab2-b9cd9b97a992",
   "metadata": {},
   "source": [
    "### Apply high pass filter to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288ed0f-8dd2-4bdf-8dda-ae72a92a0aae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#looping over wavelengths for high band pass filter\n",
    "for wavelength in [200,700]:\n",
    "    print('wavelength = ', wavelength)\n",
    "    # looping over year (2002,2003...)\n",
    "    for i in range(len(datearrs)):\n",
    "        print('year = ', datearrs[i][0].year)\n",
    "        ntsteps_per_loop = 61\n",
    "        ntsteps = len(datearrs[i])\n",
    "        tcounter = np.zeros((ntsteps//ntsteps_per_loop)+2)\n",
    "        tcounter[:-1] = np.arange(0,(ntsteps//ntsteps_per_loop)+1)*ntsteps_per_loop\n",
    "        tcounter[-1] = ntsteps\n",
    "        tcounter\n",
    "        # looping over each set of 61 time steps\n",
    "        for x in range(6):\n",
    "            print('tt vals = ', np.arange(tcounter[x],tcounter[x+1],1))\n",
    "            lazy_results = []\n",
    "            for tt in np.arange(tcounter[x],tcounter[x+1],1):\n",
    "                # define computation \n",
    "                lazy_result = dask.delayed(besselhighpass)(varfile=datafiles[i], \n",
    "                                                                         varname=varname, \n",
    "                                                                         datearr=datearrs[i], \n",
    "                                                                         tt=int(tt), \n",
    "                                                                         wavelength=wavelength)\n",
    "                # store computations to be done in parallel\n",
    "                lazy_results.append(lazy_result)  \n",
    "            # do computations in parallel\n",
    "            futures = dask.compute(*lazy_results)\n",
    "            results = dask.compute(*futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf78e25-6776-478f-8adc-35c3d84dc3c3",
   "metadata": {},
   "source": [
    "### Shutdown cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36323654-289d-41ab-9145-dec5cfb80ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66228e1b-0eca-44f4-a242-ed1c61c6b785",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytracker5",
   "language": "python",
   "name": "pytracker5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
