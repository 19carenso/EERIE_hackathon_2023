{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe5ac22b-66ce-4024-bea5-dc07f294377d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tracking eddies; to be run after identifying_eddies.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919b7b8-f397-4332-87c7-0b4ef26d083d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "from py_eddy_tracker.featured_tracking.area_tracker import AreaTracker\n",
    "from py_eddy_tracker.tracking import Correspondances\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161bf77-dd14-4d6b-8113-59382dae9666",
   "metadata": {},
   "source": [
    "### Setup SLURMCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e148ea0-9ccf-445f-9832-e0a4100b830a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f6243-7886-43f2-b7b8-b42637e5ca16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask.config.config.get('distributed').get('dashboard').update({'link':'{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bdf55-83a8-4217-a836-de379bea0002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster = SLURMCluster(name='dask-cluster',\n",
    "                      cores=10,\n",
    "                      memory='256GB',\n",
    "                      processes=5,\n",
    "                      interface='ib0',\n",
    "                      queue='compute',\n",
    "                      account='mh0033',\n",
    "                      walltime='01:00:00',\n",
    "                      asynchronous=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc654c4-5513-46db-ae5a-90692d3f23bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster.scale(cores=200)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5e1d5-b7b7-45d1-8f9a-7a77f99e15b5",
   "metadata": {},
   "source": [
    "### Define functions we want to do in parallel (eddy tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a36bc2-c975-4c40-9b68-175a0b34e3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions from eddy-tracking.py (aided by Malcolm Roberts)\n",
    "def tracking(file_objects, previous_correspondance, eddy_type, zarr=False, nb_obs_min=10, raw=True, cmin=0.05, virtual=4):\n",
    "    # %%\n",
    "    # We run a tracking with a tracker which uses contour overlap, on first time step\n",
    "    output_dir = os.path.dirname(previous_correspondance)\n",
    "    class_kw = dict(cmin=cmin)\n",
    "    if not os.path.isfile(previous_correspondance):\n",
    "        c = Correspondances(\n",
    "            datasets=file_objects, class_method=AreaTracker, \n",
    "            class_kw=class_kw, virtual=virtual\n",
    "        )\n",
    "        c.track()\n",
    "        c.prepare_merging()\n",
    "    else:\n",
    "        c = Correspondances(\n",
    "            datasets=file_objects, class_method=AreaTracker, \n",
    "            class_kw=class_kw, virtual=virtual,\n",
    "            previous_correspondance=previous_correspondance\n",
    "        )\n",
    "        c.track()\n",
    "        c.prepare_merging()\n",
    "        c.merge()\n",
    "\n",
    "    new_correspondance = previous_correspondance[:-3]+'_new.nc'\n",
    "    with Dataset(new_correspondance, \"w\") as h:\n",
    "        c.to_netcdf(h)\n",
    "\n",
    "    try:\n",
    "        # test can read new file, and then move to replace old file\n",
    "        nc = Dataset(new_correspondance, 'r')\n",
    "        os.rename(new_correspondance, previous_correspondance)\n",
    "    except:\n",
    "        raise Exception('Error opening new correspondance file '+new_correspondance)\n",
    "\n",
    "    write_obs_files(c, raw, output_dir, zarr, eddy_type, nb_obs_min)\n",
    "    \n",
    "\n",
    "def write_obs_files(c, raw, output_dir, zarr, eddy_type, nb_obs_min):\n",
    "    kw_write = dict(path=output_dir, zarr_flag=zarr, sign_type=eddy_type)\n",
    "\n",
    "    fout = os.path.join(output_dir, eddy_type+'_untracked.nc')\n",
    "    c.get_unused_data(raw_data=raw).write_file(\n",
    "        filename=fout\n",
    "    )\n",
    "\n",
    "    short_c = c._copy()\n",
    "    short_c.shorter_than(size_max=nb_obs_min)\n",
    "    short_track = short_c.merge(raw_data=raw)\n",
    "\n",
    "    if c.longer_than(size_min=nb_obs_min) is False:\n",
    "        long_track = short_track.empty_dataset()\n",
    "    else:\n",
    "        long_track = c.merge(raw_data=raw)\n",
    "\n",
    "    # We flag obs\n",
    "    if c.virtual:\n",
    "        long_track[\"virtual\"][:] = long_track[\"time\"] == 0\n",
    "        long_track.normalize_longitude()\n",
    "        long_track.filled_by_interpolation(long_track[\"virtual\"] == 1)\n",
    "        short_track[\"virtual\"][:] = short_track[\"time\"] == 0\n",
    "        short_track.normalize_longitude()\n",
    "        short_track.filled_by_interpolation(short_track[\"virtual\"] == 1)\n",
    "\n",
    "    print(\"Longer track saved have %d obs\", c.nb_obs_by_tracks.max())\n",
    "    print(\n",
    "        \"The mean length is %d observations for long track\",\n",
    "        c.nb_obs_by_tracks.mean(),\n",
    "    )\n",
    "\n",
    "    fout = os.path.join(output_dir, eddy_type+'_tracks.nc')\n",
    "    long_track.write_file(filename=fout)\n",
    "    fout = os.path.join(output_dir, eddy_type+'_short.nc')\n",
    "    short_track.write_file(\n",
    "        #filename=\"%(path)s/%(sign_type)s_track_too_short.nc\", **kw_write\n",
    "        filename=fout\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fa031-2c6e-440a-975d-5c42f3a81b81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tracking_eddytype(trackerdir,eddydir, exp_id, eddy_type, fq, zarr, nb_obs_min, raw, cmin):\n",
    "    #eddy_type='anticyclonic','cyclonic'\n",
    "    previous_correspondance = os.path.join(trackerdir, expid+'_'+eddy_type+'_'+fq+'_correspondance.nc')\n",
    "    print(previous_correspondance)\n",
    "    search = os.path.join(eddydir+expid+'_'+eddy_type+'_'+fq+'_200[2-8]????.nc')\n",
    "    print('search files ',search)\n",
    "    file_objects = sorted(glob.glob(search))\n",
    "    print('files for tracking: ', file_objects)\n",
    "    tracking(file_objects, previous_correspondance, eddy_type, zarr=zarr, nb_obs_min=nb_obs_min, raw=raw, cmin=cmin)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4905ad23-f335-4662-8f8d-eb0e7c336a02",
   "metadata": {},
   "source": [
    "### Do eddy tracking using data stored by identifying_eddies.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01316c7-28c2-4d93-b147-3c04c061a97a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expid='erc1011'\n",
    "varname='ssh'\n",
    "fq='dm'\n",
    "nb_obs_min = 10 # minimum of 10 points in track to be considered a long trajectory\n",
    "raw = True # \n",
    "cmin = 0.05 # minimum contour\n",
    "virtual = 4 # number of consecutive timesteps with missing detection allowed\n",
    "class_kw = dict(cmin=cmin)\n",
    "zarr = False\n",
    "\n",
    "lazy_results = []\n",
    "# again looping over wavelength and shape error\n",
    "for wavelength in [200,700]:\n",
    "    print('wavelength = ', wavelength)\n",
    "    for shape_error in [30,70]:\n",
    "        print('shape_error = ', shape_error)\n",
    "        eddy_dir='/path/to/eddydata/'+expid+'_eddytrack/'+'wv_'+str(int(wavelength))+'_se_'+str(int(shape_error))+'/'\n",
    "        tracker_dir=eddy_dir+'tracks/'\n",
    "        if not os.path.exists(tracker_dir):\n",
    "            os.makedirs(tracker_dir)\n",
    "        print('eddydir = ', eddy_dir)\n",
    "        print('tracker_dir = ', tracker_dir)\n",
    "        for eddy_type in ['cyclonic','anticyclonic']:\n",
    "            #define computation we want to do without doing it\n",
    "            lazy_result = dask.delayed(tracking_eddytype)(trackerdir=tracker_dir,\n",
    "                                                          eddydir=eddy_dir,\n",
    "                                                    exp_id=expid, \n",
    "                                                    eddy_type=eddy_type,\n",
    "                                                    fq=fq,zarr=zarr,nb_obs_min=nb_obs_min,\n",
    "                                                      raw=raw, cmin=cmin)\n",
    "            # store all computations to be done in parallel\n",
    "            lazy_results.append(lazy_result)  \n",
    "# compute the results\n",
    "futures = dask.compute(*lazy_results)\n",
    "results = dask.compute(*futures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea86499-3ce7-4ab4-b77a-157905316bc8",
   "metadata": {},
   "source": [
    "### shutdown cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba61b09-1fcc-4a4c-9be9-3e7e4b46ca8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.close()\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcbc8d09-f1c9-4256-8f48-1668ccb1d976",
   "metadata": {},
   "source": [
    "#Files created for each combination of wavelength and shape_error\n",
    "\n",
    "erc1011_anticyclonic_dm_correspondance.nc\n",
    "anticyclonic_untracked.nc\n",
    "anticyclonic_tracks.nc\n",
    "anticyclonic_short.nc\n",
    "erc1011_cyclonic_dm_correspondance.nc\n",
    "cyclonic_untracked.nc\n",
    "cyclonic_tracks.nc\n",
    "cyclonic_short.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da276b2a-a418-4580-85c1-17effe72a3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdf03b-7be6-429a-b76b-c58c32f7b982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd0c7c0-d380-4df5-be08-6bd55f2f3ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b5326-b685-4e15-af11-8ba18b1e74dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytracker5",
   "language": "python",
   "name": "pytracker5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
